{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932f5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3b002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%flake8_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2fcfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Phishtank scraper.\n",
    "\n",
    "Visits phishtank to collect phishing links\n",
    "based on id number in reverse order,\n",
    "then visits phishing links to\n",
    "collect screenshots and html source code.\n",
    "\"\"\"\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import zlib\n",
    "import json\n",
    "\n",
    "def check_if_phish(ID, is_valid=False, is_online=False):\n",
    "    \"\"\"Retrieve phishing link from phishtank.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ID : int\n",
    "        Phish's id on phishtank\n",
    "    is_valid : bool\n",
    "        Optional check for phishtank's 'valid' classification\n",
    "    is_online : bool\n",
    "        Optional check for phishtank's 'online' classification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    link : string\n",
    "        Phishing webpage URL\n",
    "    to_catch : bool\n",
    "        Result of optional checks\n",
    "\n",
    "    \"\"\"\n",
    "    # Catch all phishes by default\n",
    "    to_catch = True\n",
    "\n",
    "    # Go to the phishtank entry using ID\n",
    "    driver.get(\"https://phishtank.org/phish_detail.php?phish_id=\" + str(ID))\n",
    "\n",
    "    # Check if phishtank lists phish as valid\n",
    "    if is_valid:\n",
    "        valid = driver.find_element(By.XPATH,\n",
    "                                    '//div[@id=\"history\"]/table/tbody\\\n",
    "                                    /tr/td/h3').text\n",
    "        # Filter for only valid phishes\n",
    "        if valid != 'Verified: Is a phish':\n",
    "            to_catch = False\n",
    "\n",
    "    # Check if phishtank lists phish as online\n",
    "    if is_online:\n",
    "        online = driver.find_element(By.XPATH,\n",
    "                                     '//div[@id=\"widecol\"]/div/h2/span').text\n",
    "        # Filter for only online phishes\n",
    "        if online != 'is currently ONLINE':\n",
    "            to_catch = False\n",
    "    \"\"\"        \n",
    "    # User Micha sometimes uploads hundreds of fake 404 links\n",
    "    # Remove multi-line string when encountered\n",
    "    # Check if user is Micha\n",
    "    micha = driver.find_element(By.XPATH,\n",
    "                                '//div[@class=\"url\"]/span/b/a').text\n",
    "    # Filter for not Micha\n",
    "    if micha == 'Micha':\n",
    "        to_catch = False\n",
    "    \"\"\"\n",
    "    # Retrieve phishing link\n",
    "    link = driver.find_element(\n",
    "        By.XPATH, '//span[@style=\"word-wrap:break-word;\"]/b'\n",
    "    ).text\n",
    "\n",
    "    return link, to_catch\n",
    "\n",
    "\n",
    "def check_status_code(link):\n",
    "    \"\"\"Check for live URL.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    link : string\n",
    "        URL of webpage\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    is_live : bool\n",
    "        True if link's status code == 200\n",
    "\n",
    "    \"\"\"\n",
    "    # Assume link is dead\n",
    "    is_live = False\n",
    "\n",
    "    try:\n",
    "        r = requests.get(link)\n",
    "\n",
    "    # Handle non-existent domains\n",
    "    except Exception:\n",
    "        return is_live\n",
    "\n",
    "    # If domain exists, check status code\n",
    "    else:\n",
    "        if r.status_code == 200:\n",
    "            is_live = True\n",
    "            return is_live\n",
    "        else:\n",
    "            return is_live\n",
    "\n",
    "\n",
    "def collect_data(link, screenshot=True, source_code=True, way_back=False):\n",
    "    \"\"\"Collects data from phishing URL.\n",
    "\n",
    "    Collected screenshot and source code are stored in a folder\n",
    "    named after the link with 'https:' and '/' removed.\n",
    "    'http:' left in to differentiate from 'https:'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    link : string\n",
    "        URL to visit\n",
    "    screenshot : bool\n",
    "        Webpage screenshot\n",
    "    source_code : bool\n",
    "        Webpage html source code\n",
    "    way_back : bool\n",
    "        Attempt to store webpage in way back machine\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    html : string\n",
    "        html source code\n",
    "    save_loc : string\n",
    "        data storage directory\n",
    "\n",
    "    \"\"\"\n",
    "    # Create folder to store entry in collection\n",
    "    parent = f\"collection/{str(date.today())}/\"\n",
    "    directory = link.replace(\"/\", \"\")\n",
    "    directory = directory.replace(\"https:\", \"\")\n",
    "    # Make sure folder name is not too long\n",
    "    if len(directory) > 128:\n",
    "        directory = directory[:129]\n",
    "    path = os.path.join(parent, directory)\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Directory to save data\n",
    "    save_loc = f\"{str(Path.cwd())}/collection/{str(date.today())}/{directory}/\"\n",
    "    \n",
    "    # Webpage screenshot\n",
    "    if screenshot:\n",
    "        driver.get_screenshot_as_file(\n",
    "            f\"{save_loc}{directory}.png\"\n",
    "        )\n",
    "\n",
    "    # Stores html source code\n",
    "    if source_code:\n",
    "        html = driver.page_source\n",
    "        f = open(f\"{save_loc}{directory}.html\", \"w\")\n",
    "        f.write(html)\n",
    "        f.close()\n",
    "\n",
    "    # Uploads page to Wayback machine\n",
    "    if way_back:\n",
    "        driver.get(\"https://archive.org/web/\")\n",
    "        driver.find_element(\n",
    "            By.XPATH,\n",
    "            '//form[@name=\"wwwform_save\"]/input'\n",
    "        ).send_keys(link)\n",
    "        try:\n",
    "            driver.find_element(\n",
    "                By.XPATH,\n",
    "                '//button[@class=\"web-save-button web_button web_text\"]'\n",
    "            ).click()\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            driver.find_element(\n",
    "                By.XPATH,\n",
    "                '//form/input[@value=\"SAVE PAGE\"]'\n",
    "            ).click()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Stores directory and URL in text file\n",
    "    f = open(\"collected_phishes.csv\", \"a\")\n",
    "    f.write(\"\\n\" + '\"' + str(date.today())+\"/\"+directory + '\"' + \",\" + '\"' + link + '\"')\n",
    "    f.close()\n",
    "    \n",
    "    return html, save_loc\n",
    "\n",
    "def log_entry(link, collected, checksum=\"0\"):\n",
    "    \"\"\"Record collection attempt in a text file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    link : string\n",
    "        Phishing URL\n",
    "    collected : bin\n",
    "        1 for successful collection, 0 otherwise\n",
    "    checksum : string\n",
    "        checksum for successful collection, 0 otherwise\n",
    "\n",
    "    \"\"\"\n",
    "    f = open(\"collection_attempts.csv\", \"a\")\n",
    "    end = time.time()\n",
    "    time_elapsed = round((end - start), 4)\n",
    "    f.write(\n",
    "        \"\\n\"\n",
    "        + str(i)\n",
    "        + \",\"\n",
    "        + '\"'\n",
    "        + link\n",
    "        + '\"'\n",
    "        + \",\"\n",
    "        + str(collected)\n",
    "        + \",\"\n",
    "        + str(time_elapsed)\n",
    "        + \",\"\n",
    "        + checksum\n",
    "    )\n",
    "    f.close()\n",
    "\n",
    "def compare_source(link, checksum_dict):\n",
    "    \"\"\"Compares new html with collected html\n",
    "    \n",
    "    Visits link and collects html source code.\n",
    "    Maintains dictionary of collected html,\n",
    "    key: value pairs are adler32 checksum: count.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    link : string\n",
    "        URL to visit\n",
    "    checksum_dict : dict\n",
    "        Dictionary of checksums\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    checksum : string\n",
    "        adler32 checksum of html source code\n",
    "    is_new : bool\n",
    "        True if checksum did not exist in checksum_dict\n",
    "    \n",
    "    \"\"\"\n",
    "    #Visit URL\n",
    "    driver.get(link)\n",
    "    \n",
    "    #Checks html scource code against collected\n",
    "    html = str.encode(driver.page_source)\n",
    "    checksum = str(zlib.adler32(html))\n",
    "    \n",
    "    #Increase checksum count\n",
    "    if checksum in checksum_dict:\n",
    "        checksum_dict[checksum] += 1\n",
    "        is_new = False\n",
    "    else:\n",
    "        checksum_dict[checksum] = 1\n",
    "        is_new = True\n",
    "        \n",
    "    return checksum, is_new\n",
    "\n",
    "def iframe_source(html, parent):\n",
    "    \"\"\"Gets html from possible iframe sources\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    html : string\n",
    "        web page source code\n",
    "    parent : string\n",
    "        parent directory to store html from iframe\n",
    "    \n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    if soup.find(\"iframe\") is not None:\n",
    "        links_list = [tag.get(\"src\") for tag in soup.find_all(\"iframe\")]\n",
    "        for i in links_list:\n",
    "            try:\n",
    "                # Handle blobs\n",
    "                if i[:5] == \"blob:\":\n",
    "                    j = i[5:]\n",
    "                else:\n",
    "                    j = i\n",
    "                # Visit iframe source\n",
    "                driver.get(j)\n",
    "                # Specify directory to store html\n",
    "                idirectory = i.replace(\"/\", \"\")\n",
    "                idirectory = idirectory.replace(\"https:\", \"\")\n",
    "                # Get html source code and save it\n",
    "                html = driver.page_source\n",
    "                f = open(f\"{parent}{idirectory}.html\", \"w\")\n",
    "                f.write(html)\n",
    "                f.close()\n",
    "                # Get screenshot\n",
    "                driver.get_screenshot_as_file(f\"{parent}{idirectory}.png\")\n",
    "                # Look for nested iframes and repeat\n",
    "                iframe_source(html, parent)\n",
    "            except Exception:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736b311",
   "metadata": {},
   "source": [
    "# Actual stuff starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a1ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import firefox profile and allow firefox to access phishing webpages.\n",
    "options = Options()\n",
    "options.add_argument(\"-profile\")\n",
    "options.add_argument(\n",
    "    \"/home/defaultuser/snap/firefox/common\" +\n",
    "    \"/.mozilla/firefox/selenium_profile.default\"\n",
    ")\n",
    "options.set_capability(\"acceptInsecureCerts\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a6a3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start selenium\n",
    "driver = webdriver.Firefox(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ddb30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories and text files to store data\n",
    "if not os.path.exists('collected_phishes.csv'):\n",
    "    with open('collected_phishes.csv', 'w') as f:\n",
    "        f.write('directory,url')\n",
    "if not os.path.exists('collection_attempts.csv'):\n",
    "    with open('collection_attempts.csv', 'w') as f:\n",
    "        f.write('id,url,collected?,time_taken(s),checksum')\n",
    "if not os.path.exists('checksum_dict.json'):\n",
    "    with open('checksum_dict.json','w') as f:\n",
    "        f.write(\"{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80f57e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743.2525608539581"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_total = time.time()\n",
    "\n",
    "# Read existing html checksums\n",
    "with open('checksum_dict.json','r') as f:\n",
    "    checksum_dict = json.load(f)\n",
    "\n",
    "# Insert start ID as i\n",
    "i = 7657473\n",
    "\n",
    "# Insert end ID as i != end ID\n",
    "while i != 7657373:\n",
    "\n",
    "    # Start time for single id\n",
    "    start = time.time()\n",
    "    \n",
    "    # Create new date directory if running overnight\n",
    "    Path(f'collection/{date.today()}').mkdir(parents=True,exist_ok=True)\n",
    "    \n",
    "    # Check if phish\n",
    "    try:\n",
    "        link, to_catch = check_if_phish(i)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    # Filter for 'valid' or 'online' if they are set.\n",
    "    if not to_catch:\n",
    "        log_entry(link, 0)\n",
    "\n",
    "    else:\n",
    "        # Check if link is dead\n",
    "        is_live = check_status_code(link)\n",
    "        if not is_live:\n",
    "            log_entry(link, 0)\n",
    "\n",
    "        else:\n",
    "            # Check if html has been collected\n",
    "            try:\n",
    "                checksum, is_new = compare_source(link, checksum_dict)\n",
    "            except Exception:\n",
    "                log_entry(link, 0)\n",
    "            \n",
    "            if is_new:\n",
    "                # Collect the phish if html is new\n",
    "                try:\n",
    "                    html, save_loc = collect_data(link)\n",
    "                    log_entry(link, 1, checksum=checksum)\n",
    "                except Exception:\n",
    "                    log_entry(link, 0, checksum=checksum)\n",
    "                # Collect from possible iframe sources\n",
    "                iframe_source(html, save_loc)\n",
    "                \n",
    "            else:\n",
    "                log_entry(link, 0, checksum=checksum)\n",
    "\n",
    "    i -= 1\n",
    "\n",
    "# Calculate total time\n",
    "end_total = time.time()\n",
    "total_time = end_total - start_total\n",
    "total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95b9e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete old dictionary file and write a new one\n",
    "os.remove('checksum_dict.json')\n",
    "with open('checksum_dict.json','w') as f:\n",
    "    json.dump(checksum_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Started 2022-08-16 at ID 7657582"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
